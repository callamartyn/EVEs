{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapted from https://github.com/AnneliektH/EVEs_arthropod/blob/master/parse_xml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rownames = ['query', 'subject', 'per_id', 'length', 'mismatch', 'gap_open', 'q_start', 'q_end', 's_start', 's_end', 'evalue', 'bitscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/callamartyn/chou_lab/EVE/out/Iscap_blastx_vprot_1e-03.tsv', sep = '\\t', header=None, names = rownames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to replace first part of BLAST_filter.sh (making a bed file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get query start and end positions from full table\n",
    "bed = df.iloc[:,[0,6,7]]\n",
    "#write out to a tsv with bed file suffix\n",
    "bed.to_csv('/Users/callamartyn/chou_lab/EVE/out/bed_files/test.bed', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuring out how to filter duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dup(df):\n",
    "    df.sort_values('evalue', inplace=True)\n",
    "    df.drop_duplicates(['query', 'q_start', 'q_end'], inplace=True, keep=\"first\")\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup = remove_dup(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering overlapping hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overlap(df):\n",
    "    df_grouped=df.groupby('query')\n",
    "    # list to store index that are either unique enough or have highest evalue\n",
    "    results = []\n",
    "    # list to save those that have already been added so they can be skiped\n",
    "    to_be_skipped = []\n",
    "\n",
    "    for group_name, df_group in df_grouped:\n",
    "\n",
    "        for index, row in df_group.iterrows():\n",
    "\n",
    "            # check if sequence or simmilar sequence already added\n",
    "            if index in to_be_skipped:\n",
    "                continue\n",
    "\n",
    "            # initialize empty simmilar dict\n",
    "            similar = {}\n",
    "\n",
    "            for index2, row2 in df_group.iterrows():\n",
    "\n",
    "                # check if possition start or stop is equal and is not self.\n",
    "                if index == index2:\n",
    "                    continue\n",
    "\n",
    "                # check if possition start or stop is equal and is not self.\n",
    "                    # if entry is comparing to itself\n",
    "                if row[7] == row2[7] and row2[8] == row[8]:\n",
    "                    continue\n",
    "\n",
    "                elif (row[7] in range(row2[7], row2[8]) or\n",
    "                row2[7] in range(row[7], row[8]) or\n",
    "                row[8] in range(row2[7], row2[8]) or\n",
    "                row2[8] in range(row[7], row[8])):\n",
    "                    # add both indexes of simmilar sequences plus their score to the dict\n",
    "                    similar[index] = row[10]\n",
    "                    similar[index2] = row2[10]\n",
    "\n",
    "            # check if simmilar sequences have been found\n",
    "            if len(similar) > 0:\n",
    "\n",
    "                # get the max score from the simmilar sequences\n",
    "                max_index = max(similar, key=similar.get)\n",
    "\n",
    "                # add index with maximum score to results list\n",
    "                results.append(max_index)\n",
    "\n",
    "                # add checked indices to be skipped list\n",
    "                for k,v  in similar.items():\n",
    "                    to_be_skipped.append(k)\n",
    "\n",
    "            # if seqeunce is unique add index to results\n",
    "            if len(similar) == 0:\n",
    "                results.append(index)\n",
    "                to_be_skipped.append(index)\n",
    "    return df.loc[results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique = remove_overlap(df_dedup)\n",
    "len(df_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('/Users/callamartyn/chou_lab/EVE/out/test_unique.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
